---
layout: default
tags: about
---
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script type="text/javascript">
function readMore() {
    $('#readMore').hide();
    $('#more').show();
}
function readLess() {
    $('#readMore').show();
    $('#more').hide();
}
</script>

<img src="images/circle-cropped (6).png" alt="Vaishnavi Khindkar" width="240" style="float: right; padding: 20px; border-radius: 50%;" />

<div class="bio" style="text-align:justify">

<p>I'm a Research Fellow in computer vision and deep learning at the <a href="https://cvit.iiit.ac.in">Center for Visual Information Technology (CVIT)</a>, IIIT Hyderabad. I have been working in autonomous driving domain using computer vision and deep learning for a span of two years under the guidance of excellent team of advisors, <a href="https://faculty.iiit.ac.in/~jawahar/">Prof. C V Jawahar</a>, <a href="https://www.iith.ac.in/~vineethnb/">Prof. Vineeth N Balasubramanian</a>, <a href="https://www.cse.iitd.ac.in/~chetan/">Prof. Chetan Arora</a> and <a href="https://www.intel.com/content/www/us/en/artificial-intelligence/bios/anbumani-subramanian.html">Dr. Anbumani Subramanian</a>. It has been a really great learning experience to grow in this field, that I am extremely passionate about. I worked on various amazing projects in this span of time. One of which has been published at WACV 2022 conference and other is under review at ECCV. One of our works is also under patenting process. I have also have been a reviewer at WACV conference. Overall it has really been a wonderful experience. Previously I had been working in IT sector at Barclays Inc., where I had good exposure to develop end-to-end systems and understand how things work at corporate level. It was a drastic career change (from Barclays to CVIT, IIITH), that I worked hard for; to pursue my passion as my profession and grow further in that path. I completed my Bachelors in Computer Science and Engineering in 2018 from Savitribai Phule Pune University (SPPU), India where I was advised by <a href="https://scholar.google.co.in/citations?user=IrfavGQAAAAJ&hl=en">Dr. Sudeep Thepade
</a>.
</p>
<br>

<p><strong>Research Interests: <span style="color:gray">Back during my undergraduate course in Computer Science, I used to wonder, "What really would be the next revolution in this field?" Back then enjoying my programming courses and being dramatically fascinated by technologies like Jarvis, Siri I thought, Mind Reading Computers would just be the next remarkable revolution. Curiosity about developing Mind-Reading Computers drove me towards emerging world-changing technologies in the field of Artificial Intelligence. I am fascinated by research works in object-Object interactions or Object-Scene interactions and their relationship / intent understanding. My current research work lies in the intersection of vision and language, using explainable AI for problems like pedestrian intent prediction and further exploring visual and abductive reasoning for the same. Some of my previous research works include interesting domains like unsupervised domain adaptation, spatio-temporal reasoning using graph neural networks, generative adversarial networks to name a few.</p></span></strong>

<p><strong>Volunteering: <span style="color:gray">I belive in giving back to the society what we are fortunate enough to have gained. I am selected to be a Portfolio Project Mentor for the Changemakers in AI program at AI4ALL. Excited to spend my summer mentoring the students at a platform like AI4ALL, it's a two-way learning process I believe. Previously I had also organised Organised HOUR OF CODE as an initiative for International Coding Week, to teach school students Coding and Algorithmic Concepts by innovative and simple games.</p></span></strong>

<p> My non-professional interests include watching Sci-Fi movies, Favourite being Iron Man. Reading a lot about new tech stuffs as well as trending articles and implementations related to my field of interest on Google and Twitter. I’m always up for interesting collaborations or just random chats on AI, feel free to drop me a message on Linkedin or via email.</p>

<br/>

<div class="container">
  <div class="row" style="text-align:center;">
        <div class="col">
          <a href="https://ai-4-all.org/"><img src="images/ai4all.png" style="max-height:150px;width:90%"></a>
        </div>
        <div class="col" style="text-align:center;">
          <a href="https://www.iiit.ac.in/"><img src="images/IIITH.png" style="max-height:500px;width:100%"></a>
        </div>
        <div class="col">
          <a href="https://cvit.iiit.ac.in/"><img src="images/cvit.png" style="width:80%;max-height:150px"></a>
        </div>      
        <div class="col" style="text-align:center;">
          <a href="https://home.barclays/"><img src="images/barclays.png" style="width:100%;max-height:500px"></a>
        </div>
        <div class="col">
          <a href="http://www.unipune.ac.in/"><img src="images/sppu.png" style="width:100%;max-height:150px"></a>
        </div>
  </div>
  <div class="row" style="text-align:center;">
        <div class="col">
          <div style="padding:10px"><h6>Summer 2022</h6></div>
        </div>
        <div class="col">
          <div style="padding:10px"><h6>Aug 2020-Current</h6></div>
        </div>
        <div class="col">
          <div style="padding:10px"><h6>Aug 2020-Current</h6></div>
        </div>
        <div class="col">
          <div style="padding:10px"><h6>2018-2020</h6></div>
        </div>
        <div class="col">
          <div style="padding:10px"><h6>2015-2018</h6></div>
        </div>
  </div>
</div>

<!-- <hr/> -->
<br/>

<div id="research">
<h2><a name="research">Research</a></h2>
<br/>

<table width="100%" align="center" valign="middle" cellspacing="0" cellpadding="0" style="border-collapse: collapse;">
    <tbody>
      <tr>
      <td width="40%">
        <div class="one" style="text-align:center;">
            <img src="images/FINALUPDTeaserPIE++.png" style="max-height: 2900px;">
        </div>
      </td>
      <td valign="top" width="60%">
        <h5>
        Why did the chicken cross the road?
        </h5>
        <p class="authors">
        <b>Vaishnavi Khindkar</b>, Vineeth N Balasubramanian, Chetan Arora, Anbumani Subramanian, C V Jawahar
        </p>
        <p>
        Under Review
        </p>
        <p> Understanding pedestrians’ intention is crucial for safe navigation to avoid risks or uncertainties. We explore the complex problem of intent prediction with intuitive and reasonable understanding of socio-environmental interactions. </p>          
        <p>
      </td>
    </tr>
    <tr>
      <td width="30%">
        <div class="one" style="text-align:center;">
            <img src="images/FArchcorrect.png" style="max-height: 400px;">
        </div>
      </td>
      <td valign="top" width="70%">
        <h5>
        To miss-attend is to misalign! Residual Self-Attentive Feature Alignment for Adapting Object Detectors
        </h5>
        <p class="authors">
        <b>Vaishnavi Khindkar</b>, Vineeth N Balasubramanian, Chetan Arora, Anbumani Subramanian, Rohit Saluja, C V Jawahar
        </p>
        <p>
        IEEE Winter Conference on Applications of Computer Vision, WACV 2022
        </p>
        <p>
        <a href="https://openaccess.thecvf.com/content/WACV2022/papers/Khindkar_To_Miss-Attend_Is_to_Misalign_Residual_Self-Attentive_Feature_Alignment_for_WACV_2022_paper.pdf">Paper / </a>
        <!-- <i><a href="https://arxiv.org/abs/2110.12205">arxiv / </a></i> -->
        <a href="https://youtu.be/sbUWeQJ3lys">Talk / </a>
        <a href="https://github.com/Vaishnvi/ILLUME">Code / </a>
        <a href="https://docs.google.com/presentation/d/1S0Ei25aynJETC15JXNUsN_vqxQG_izMR4h-G5N1Qu1w/edit?usp=sharing">Poster / </a>
        <a href="https://openaccess.thecvf.com/content/WACV2022/supplemental/Khindkar_To_Miss-Attend_Is_WACV_2022_supplemental.pdf">Supplementary</a>
        </p>
        <!-- <a href="https://openaccess.thecvf.com/content/WACV2022/papers/Garg_Multi-Domain_Incremental_Learning_for_Semantic_Segmentation_WACV_2022_paper.pdf" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">paper</a>
        <a href="https://arxiv.org/abs/2110.12205" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">arxiv</a>
        <a href="https://www.youtube.com/watch?v=YQC5KLZUpyc" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">video</a>
        <a href="https://github.com/prachigarg23/MDIL-SS" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">code</a>
        <a href="reports/294-wacv-poster.pdf" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">poster</a>
        <a href="https://openaccess.thecvf.com/content/WACV2022/supplemental/Garg_Multi-Domain_Incremental_Learning_WACV_2022_supplemental.pdf" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">supplementary</a> -->
        <p>adaptive object detection remains challenging due to visual diversity in background scenes and intricate combinations of objects. Motivated by structural importance, we aim to attend prominent instance-specific regions, overcoming the feature misalignment issue. We propose a novel resIduaL seLf-attentive featUre alignMEnt ( ILLUME ) method for adaptive object detection. ILLUME comprises Self-Attention Feature Map (SAFM) module that enhances structural attention to object-related regions and thereby generates domain invariant features. Our approach significantly reduces the domain distance with the improved feature alignment of the instances. </p>
        </td>
    </tr>
    <tr>        
    <td width="30%">
      <div class="one" style="text-align:center;">
          <img src="images/gamma.png" style="max-height: 200px;">
      </div>
    </td>
    <td valign="top" width="70%">
      <h5>
      GAMMA : Generative Augmentation for Attentive Marine Debris Detection
      </h5>
      <p class="authors">
      <b>Prachi Garg</b>, Janhavi Khindkar
      </p>
      <p>
      Under Review
      </p>        
      <!-- <p>
        <a href="https://www.linkedin.com/pulse/towards-ai-infused-system-personalization-video-content-madaan/?articleId=6699399407223218177">Blog-post / </a>
        <a href="https://drive.google.com/drive/folders/1DVUCCE7OLlA7nFbgsf3VanIH_pZRprrq?usp=sharing">Demo / </a>
        <a href="https://kidify-ibm.herokuapp.com/survey.html">Survey</a>
      </p> -->
      <p>We propose an efficient and generative augmentation approach to solve the inadequacy concern of underwater debris data for visual detection. We use cycleGAN as a data augmentation technique to convert openly available, abundant data of terrestrial plastic to underwater-style images. Prior works just focus on augmenting or enhancing existing data, which moreover adds bias to the dataset. Compared to our technique, which devises variation, transforming additional in-air plastic data to the marine background. </p>
      <!-- <a href="https://www.linkedin.com/pulse/towards-ai-infused-system-personalization-video-content-madaan/?articleId=6699399407223218177" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">Blog-post</a>
      <a href="https://drive.google.com/drive/folders/1DVUCCE7OLlA7nFbgsf3VanIH_pZRprrq?usp=sharing" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">Demo</a>
      <a href="https://kidify-ibm.herokuapp.com/survey.html" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">Survey</a> -->
    </td>
  </tr>
  <tr>
  <td width="30%">
    <div class="one" style="text-align:center;">
        <img src="images/iot1.jpeg" style="max-height: 200px;">
    </div>
  </td>
  <td valign="top" width="70%">
    <h5>
    IOT based Smart Home using Face Recognition 
    </h5>
    <p class="authors">
    <b>Vaishnavi Khindkar</b>, Aishwarya Koppella, Ashwini Adhau, Sharayu Pardeshi, Mahalaxmi Reddy
    </p>
    <p>
    <a href="https://www.ijcrt.org/papers/IJCRT1802045.pdf">Paper / </a>
    <a href="https://github.com/Vaishnvi/IOT-based-Smart-Home-using-Face-Recognition">Code / </a>
    </p>
    <p>This project provides controlling and monitoring of home appliances as well as provides security from unknown persons. We proposed a system for Smart Home Automation technique. To design this system, we used a Raspberry Pi module and Computer Vision techniques, OpenCV and image processing algorithms.</p>
  </td>
  </tr>
  <tr>
  <td width="30%">
    <div class="one" style="text-align:center;">
        <img src="images/ucmerced.jpeg" style="max-height: 200px;">
    </div>
  </td>
  <td valign="top" width="70%">
    <h5>
    Multiclass Image classication on UC-Merced LandUse Dataset
    </h5>
    <p class="authors">
    <b>Vaishnavi Khindkar</b>
    </p>
    <p>
      <!-- <a href="http://sersc.org/journals/index.php/IJAST/article/view/22330/11234">Paper / </a> -->
      <a href="https://github.com/Vaishnvi/Multiclass-Image-classication-on-UC-Merced-LandUse-Dataset-">Code / </a>
    </p>
    <p>
    This project aims at classification of remote sensing image dataset. The model developed for classification is a fusion model of spatial features with dct features.3-layer fusion model of cnn is used with dct and lbp to improve the accuracy of prediction. Various accuracy enchancing techniques like augmentation and feature level fusion of dct and lbp are used Project contains various ipynb notebooks tried on the dataset.
    </p>
  </td>
  </tr>
  <tr>
  <td width="30%">
    <div class="one" style="text-align:center;">
        <img src="images/nps.jpeg" style="max-height: 200px;">
    </div>
  </td>
  <td valign="top" width="70%">
    <h5>
    Aspect Based Sentiment Analysis on NPS survey data for Retail Online Banking
    </h5>
    <p class="authors">
    <b>Vaishnavi Khindkar</b>, Suchita Jadhav
    </p>
    <p>
    Implemented an aspect based Sentiment Analysis on NPS (Net Performer Score) Survey Data for Retail Online Banking Platform to understand reviews of customers on Online Banking features like Payments or Homepage etc. Also created a Dashboard in AngularJs to display visualisations on sentiments of Customers for different features.It helped in analysing what improvements can be done by analysing the negative reviews for the particular features.        
    </p>
    <!-- While visual analytics plays an essential role in wildlife monitoring, camera trap images from unconstrained wild environments pose several challenges for species detection and classification.  Most existing models show poor generalisation on the test set domains  due to drastic domain shifts, transfer learning is difficult. We conducted experiments with modified versions of state-of-the-art object detection frameworks, incorporating concepts such as receptive field blocks from RBFNet, feature pyramid pooling from FPN, and DA-FRCNN aimed at training a model that learns a richer feature representation so as to bridge the gap between cis and trans performance for animal detection in the <a href="https://beerys.github.io/CaltechCameraTraps/">Catech Camera Traps dataset (CCT20)</a>. -->
    <p><small>More details about my research journey can be found <a href="https://docs.google.com/presentation/d/1o9Nt6HDZWnIzwLGqx8OFmO7bn3mIoCXweBQaR7h5lWQ/edit?usp=sharing">here</a>.</small></p>
  </td>
  </tr>
  </tbody>
</table>
</div>

<br/>


<div id="talks">
<h2>News and Miscellaneous</h2>
<table width="100%" align="center" valign="middle" cellspacing="0" cellpadding="0" style="border-collapse: collapse;">
    <tbody>
      <tr>
      <td width="20%">
        <h5>
          January, 2022
        </h5>
      </td>
      <td valign="middle" width="80%">
        <h5>
        Presented our work on 'Multi-domain incremental learning for semantic segmentation' at WACV 2022
        </h5>
      </td>
      </tr>
      <tr>
      <td width="20%">
        <h5>
          December, 2021
        </h5>
      </td>
      <td valign="middle" width="80%">
        <h5>
        Funded to be a Super Volunteer, WiML Workshop @ NeurIPS 2021; Attended NeurIPS 2021 Workshop on Machine Learning for Autonomous Driving
        </h5>
      </td>
      </tr>
      <tr>
      <td width="20%">
        <h5>
          August, 2021
        </h5>
      </td>
      <td valign="middle" width="80%">
        <h5>
        Sub Reviewer, BMVC 2021
        </h5>
      </td>
      </tr>
      <tr>
      <td width="20%">
        <h5>
          September, 2020
        </h5>
      </td>
      <td valign="middle" width="80%">
        <h5>
        Gave a tutorial on Geometric Deep Learning and Graph Convolutional Networks (GCN)
        </h5>
        <p class="authors">
        Reading Group: Vision for Mobility and Safety
        <br>
        <a href="reports/GCN-Tutorial-Wed-meeting.pdf">Slides</a>
        </p>
      </td>
      </tr>
  </tbody>
</table>
</div>
<hr>
<p align="right">
<small>Forked and modified from <a href="https://virajprabhu.github.io/">Viraj Prabhu's</a> adaptation of <a href="https://github.com/johno/pixyll">Pixyll</a> theme</a></small></p>
